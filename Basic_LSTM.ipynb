{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TejasviniAditya\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.optimizers import RMSprop, SGD\n",
    "from keras.layers import Bidirectional\n",
    "from keras.utils import np_utils\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_units = 50\n",
    "batch_size = 128\n",
    "n_classes = 10\n",
    "n_epochs = 5\n",
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "data = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "\n",
      "MNIST data loaded: train samples: 60000 test samples: 10000\n",
      "X_train_lstm shape: (60000, 28, 28)\n",
      "X_train_cnn shape: (60000, 28, 28, 1)\n",
      "Y_train shape: (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# prep for LSTM\n",
    "X_train_lstm = X_train.astype('float32')\n",
    "X_test_lstm = X_test.astype('float32')\n",
    "X_train_lstm /= 255\n",
    "X_test_lstm /= 255\n",
    "print(X_train.shape)\n",
    "input_shape_lstm = X_train_lstm.shape[1:]\n",
    "\n",
    "# prep for cnn\n",
    "X_train_cnn = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "X_test_cnn = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "X_train_cnn = X_train_cnn.astype('float32')\n",
    "X_test_cnn = X_test_cnn.astype('float32')\n",
    "X_train_cnn /= 255\n",
    "X_test_cnn /= 255\n",
    "input_shape_cnn = X_train_cnn.shape[1:]\n",
    "\n",
    "# convert to one-hot encoding\n",
    "Y_train = np_utils.to_categorical(Y_train, n_classes)\n",
    "Y_test = np_utils.to_categorical(Y_test, n_classes)\n",
    "\n",
    "print()\n",
    "print('MNIST data loaded: train samples:',len(X_train_lstm),'test samples:',len(X_test_lstm))\n",
    "print('X_train_lstm shape:', X_train_lstm.shape)\n",
    "print('X_train_cnn shape:', X_train_cnn.shape)\n",
    "print('Y_train shape:', Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Single Layer LSTM on the MNIST data\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(LSTM(hidden_units, input_shape=input_shape_lstm))\n",
    "model_lstm.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "model_lstm.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 23s 392us/step - loss: 0.7792 - acc: 0.7523 - val_loss: 0.2968 - val_acc: 0.9131\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 23s 379us/step - loss: 0.2357 - acc: 0.9313 - val_loss: 0.1933 - val_acc: 0.9411\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 23s 389us/step - loss: 0.1632 - acc: 0.9520 - val_loss: 0.1410 - val_acc: 0.9571.1674 - acc: 0.950 - ETA: 5s - loss: 0.1674  - ETA: 4s \n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 23s 385us/step - loss: 0.1276 - acc: 0.9627 - val_loss: 0.1139 - val_acc: 0.9653\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 24s 393us/step - loss: 0.1066 - acc: 0.9686 - val_loss: 0.1074 - val_acc: 0.9682\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20402534e48>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lstm.fit(X_train_lstm, Y_train, batch_size=batch_size, epochs=n_epochs,\n",
    "          verbose=1, validation_data=(X_test_lstm, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM test score: 0.10735782951414585\n",
      "LSTM test accuracy: 0.9682\n"
     ]
    }
   ],
   "source": [
    "scores = model_lstm.evaluate(X_test_lstm, Y_test, verbose=0)\n",
    "print('LSTM test score:', scores[0])\n",
    "print('LSTM test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv = Sequential()\n",
    "model_conv.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape_cnn))\n",
    "model_conv.add(Flatten())\n",
    "\n",
    "model_conv.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "model_conv.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 45s 745us/step - loss: 0.2603 - acc: 0.9254 - val_loss: 0.1209 - val_acc: 0.9659\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 43s 714us/step - loss: 0.0961 - acc: 0.9734 - val_loss: 0.0785 - val_acc: 0.9761\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 44s 734us/step - loss: 0.0687 - acc: 0.9800 - val_loss: 0.0690 - val_acc: 0.9785\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 44s 732us/step - loss: 0.0560 - acc: 0.9839 - val_loss: 0.0696 - val_acc: 0.9789\n",
      "Epoch 5/5\n",
      "25088/60000 [===========>..................] - ETA: 23s - loss: 0.0475 - acc: 0.9862"
     ]
    }
   ],
   "source": [
    "model_conv.fit(X_train_cnn, Y_train, batch_size=batch_size, epochs=n_epochs,\n",
    "          verbose=1, validation_data=(X_test_cnn, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model_conv.evaluate(X_test_cnn, Y_test, verbose=0)\n",
    "print('LSTM test score:', scores[0])\n",
    "print('LSTM test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
